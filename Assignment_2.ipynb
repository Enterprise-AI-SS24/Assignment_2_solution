{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='bar_title'></div>\n",
    "\n",
    "*Enterprise AI*\n",
    "\n",
    "# Assignment 2 - ZenML & Feature Engineering\n",
    "Gunther Gust / Justus Ameling<br>\n",
    "Chair of Enterprise AI\n",
    "\n",
    "Summer Semester 24\n",
    "\n",
    "<img src=\"https://github.com/GuntherGust/tds2_data/blob/main/images/d3.png?raw=true\" style=\"width:20%; float:left;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment we look at ZenML for the first time. ZenML is an open source machine learning lifecycle management tool that aims to simplify the workflow from development to production. It enables data scientists and engineers to create reproducible pipelines that ensure consistent and comparable experiments. With its modular architecture, ZenML supports the integration of different ML tools and frameworks, making it a flexible solution for a wide range of deployment scenarios.\n",
    "\n",
    "Our objective for this assignment is to develop a training pipeline to predict whether it will rain in Perth, Australia, tomorrow. To achieve this, our pipeline will load the necessary data, perform feature engineering, build a model, and evaluate it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, before we can start setting up our pipeline, we need to run three commands.\n",
    "- The first one is `!rm -rf .zen'. This command will remove the .zen folder and all its subfolders. So we use this command to start with a fresh zenML repository.\n",
    "- The `!zenml init' command creates this repo for us by creating a folder that contains a YAML file at the beginning.\n",
    "- The last command `!zenml integration install sklearn -y` is used to install the sklearn library with the appropriate version to be used with ZenML.\n",
    "    - ZenML is capable of working with several libraries, and Sklearn is just one of them - <a href=\"https://www.zenml.io/integrations\">see more</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf .zen\n",
    "!zenml init\n",
    "!zenml integration install sklearn -y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we need to understand our dataset. Thus, let us load the  `Weather_Perth.csv` file with the pandas library and apply the three following descriptive measures:\n",
    "- Print the first 5 lines with the head command\n",
    "- Print the dtypes of all columns\n",
    "- Print the number of null values per column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None) #This command allows us to inspect all the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = #Load the DataFrame\n",
    "# Print the head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print the number of null values per column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ZenML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a good understanding of our data, we can begin developing our Pipeline. A ZenML **pipeline** comprises of multiple **steps** that are necessary for a successful ML process. Each step in the pipeline represents a different task, such as data loading, feature engineering, or model tuning. We can define these steps by writing functions that adhere to the framework's requirements. Once we've constructed all of the steps, we can combine them into a single Python function that represents our pipeline.\n",
    "\n",
    "Let's begin by importing some more packages, and then let us look at the first step of our future pipeline in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zenml import pipeline, step\n",
    "from typing_extensions import Annotated\n",
    "from typing import Tuple\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first step is the `loading_data` function, which loads our CSV file using the panda's library. To understand the concept of ZenML better, we will drill down all the parts from top to bottom.\n",
    "\n",
    "1. *Decorator*: `@step(enable_cache=False)`\n",
    "    - The decorator will wrap our function in the background into another function and thus transform it into a step.\n",
    "    - Steps have some additional functionality, and one of them is caching, which allows us to skip the execution of a function when no new information is available.\n",
    "        - For this function, we have turned off caching since it cannot prove if external objects have changed <a href=\"https://docs.zenml.io/user-guide/starter-guide/cache-previous-executions\"> see more</a>\n",
    "2. *Function Header*: `def loading_data(filename: str) -> Annotated[pd.DataFrame,\"data_loader\"]:`\n",
    "    - The next interesting thing about ZenML is that it stores all inputs and outputs of our steps as <a href=\"https://docs.zenml.io/getting-started/core-concepts#artifacts\">Artifacts</a>. For this purpose, ZenML wants to know the type of arguments - <a href=\"https://docs.python.org/3/library/typing.html\"> see more</a>\n",
    "    - Our input parameter `filename` has the type String (str) \n",
    "    - Our return value of the function is a `pd.DataFrame`, and we have additionally given it the name `input_data` so that we can retrieve it later faster.\n",
    "3. *Function Body*: \n",
    "    - We use the already-known pandas function to retrieve our CSV file. After that, we return the constructed DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@step(enable_cache=False)\n",
    "def loading_data(filename: str) -> Annotated[pd.DataFrame,\"input_data\"]:\n",
    "    \"\"\" Loads a CV File and transforms it to a Pandas DataFrame\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(filename,index_col=\"Date\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our next step will use the loaded DataFrame and an attribute `label` to split our data into a train and test set. Therefore, we can use the `train_test_split` method from the sklearn library. Additionally, since our data is sorted by date, we want the last 20% of the data as our test set. To avoid shuffling the data, which is a default option for the train_test_split method, we must pass the argument `shuffle=False` with the function. Finally, the function will return the four variables, which are described again in the function header for the step function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@step\n",
    "def split_data(dataset:pd.DataFrame, label: str) -> Tuple[\n",
    "    Annotated[pd.DataFrame,\"X_train\"],\n",
    "    Annotated[pd.DataFrame,\"X_test\"],\n",
    "    Annotated[pd.Series,\"y_train\"],\n",
    "    Annotated[pd.Series,\"y_test\"]]:\n",
    "    \"\"\"\n",
    "    Splits a dataset into training and testing sets.\n",
    "\n",
    "    This function takes a pandas DataFrame and a specified label column, then\n",
    "    divides the data into training and testing subsets. The splitting process does\n",
    "    not shuffle the data, which preserves the original ordering in the training\n",
    "    and testing sets.\n",
    "    \"\"\"\n",
    "    X = dataset.drop(label,axis=1)\n",
    "    Y = dataset[label]\n",
    "    X_train,X_test,y_train,y_test = # Creat the train test split\n",
    "    return X_train,X_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have seen in the beginning, our dataset contains null values. Thus, we want to define a step that eliminates all of them. Our Step function should, therefore, impute all numerical values with a simple median strategy and all non-numerical values with a most frequent strategy. Both Imputers should be applied on the train and test set, which are finally returned. Hint: Have a look at assignment one again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@step\n",
    "def impute_missing_values(X_train:pd.DataFrame,X_test:pd.DataFrame) -> Tuple[Annotated[pd.DataFrame,\"X_train_imputed\"],Annotated[pd.DataFrame,\"X_test_imputed\"]]:\n",
    "    \"\"\"\n",
    "    Imputes missing values in training and testing datasets.\n",
    "\n",
    "    This function separately imputes missing values in categorical and numerical\n",
    "    columns of the provided dataframes. For numerical columns, the median of the\n",
    "    column is used to replace missing values. For categorical columns, the most frequent\n",
    "    value in the column is used as the replacement.\n",
    "    \"\"\"\n",
    "    categorical_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "    numerical_imputer = #Create the Simple Imputer with a Median Strategy\n",
    "    categorical_columns = X_train.select_dtypes(include=\"object\").columns\n",
    "    numerical_columns = # Select the numeric columns\n",
    "    # CODE HERE\n",
    "    # Apply the imputer on the train and test set\n",
    "    # CODE HERE\n",
    "    return X_train,X_test "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next feature engineering step is the encoding of the categorical variables. We want to create a step that applies one-hot encoding on all categorical variables on the train and test set to handle our categorical values. Finally, the function must return the train and test set, replacing the original categorical columns with the one-hot-encoded values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@step\n",
    "def encode_categorical_values(X_train:pd.DataFrame,X_test:pd.DataFrame) -> Tuple[Annotated[pd.DataFrame,\"X_train_encoded\"],Annotated[pd.DataFrame,\"X_test_encoded\"]]:\n",
    "    \"\"\"\n",
    "    Encodes categorical columns in the training and testing datasets using one-hot encoding.\n",
    "\n",
    "    This function identifies all columns with data type 'object' in the training dataset as\n",
    "    categorical and applies one-hot encoding to these columns. The one-hot encoded columns\n",
    "    replace the original categorical columns in both datasets. The encoder is fitted only on\n",
    "    the training data to avoid data leakage into the testing set.\n",
    "    \"\"\"\n",
    "    one_hot_encoder = #Create the OneHotEncoder with sparse_output set to False\n",
    "    categorical_columns = X_train.select_dtypes(include=\"object\").columns\n",
    "    # CODE HERE\n",
    "    # Apply the encoder on the train and test set\n",
    "    # CODE HERE\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next feature engineering step we want to conduct in our pipeline is Label encoding. We are using LabelEncoding since our target Variable `RainTomorrow` is presented by text. Thus, LabelEncoding will transform the 'No' and 'Yes values to 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@step\n",
    "def label_encoding(y_train:pd.Series,y_test:pd.Series) -> Tuple[Annotated[pd.Series,\"y_train_encoded\"],Annotated[pd.Series,\"y_test_encoded\"]]:\n",
    "    \"\"\"\n",
    "    Applies label encoding to the target variable for both training and testing datasets.\n",
    "\n",
    "    This function converts target labels into a numerical format using label encoding.\n",
    "    The encoder is fitted on the training data to ensure consistency in encoding between\n",
    "    the training and testing sets, preventing data leakage.\n",
    "    \"\"\"\n",
    "    encoder = # Create the LabelEncoder\n",
    "    y_train = pd.Series(encoder.fit_transform(y_train))\n",
    "    y_test = # Apply the Label encoder on the test set\n",
    "    return y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last feature engineering step we are applying is the scaling of the values. Therefore, we are using a `MinMaxScaler` that scales the values between 1 and 0. The scaling method is applied again on both datasets, which are finally also returned as a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@step \n",
    "def scale_values(X_train:pd.DataFrame,X_test:pd.DataFrame) -> Tuple[Annotated[pd.DataFrame,\"X_train_scaled\"],Annotated[pd.DataFrame,\"X_test_scaled\"]]:\n",
    "    \"\"\"\n",
    "    Scales numerical features to a range between 0 and 1 using MinMax scaling.\n",
    "\n",
    "    This function applies MinMaxScaler to scale the feature values in both the training\n",
    "    and testing datasets. The scaler is fitted only on the training data to prevent data leakage from the test set.\n",
    "    \"\"\"\n",
    "    scaler = #Create the MinMaxScaler\n",
    "    X_train = pd.DataFrame(scaler.fit_transform(X_train),index=X_train.index, columns=X_train.columns)\n",
    "    X_test = # Apply the sclaer on the test set\n",
    "\n",
    "    return X_train,X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have prepared all the necessary steps to create a clean and usable dataset, we can develop and evaluate our machine-learning model. Hence, two final steps we need to define are left over before we stack everything together to execute our pipeline.\n",
    "\n",
    "To train our model, we define the `model_trainer` step. As input, it receives the `X_train` features and the labels given by `y_train`. Then, a `LogisticRegression` is created inside the step and fitted to the training data. Lastly, the step returns as an artifact the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@step\n",
    "def model_trainer(X_train: pd.DataFrame, y_train: pd.Series)-> Tuple[Annotated[ClassifierMixin,\"Model\"],Annotated[float,\"In_Sample_Accuracy\"]]:\n",
    "    \"\"\"\n",
    "    Trains a logistic regression model using the provided training data and computes the in-sample accuracy.\n",
    "    \"\"\"\n",
    "    model = # Create the Model\n",
    "    # Fit the model\n",
    "    in_sample_score = model.score(X_train,y_train)\n",
    "    return model,in_sample_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we need to evaluate the performance of our model. For this performance test, we are creating the last step for our pipeline. This step has three input arguments: The model that our `model_trainer` returns, the cleaned features of the test set, and the corresponding labels. Overall, the `evaluate_model` step should calculate the accuracy of our model on the test dataset and return the metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@step\n",
    "def evaluate_model(model:ClassifierMixin,X_test:pd.DataFrame,y_test:pd.DataFrame) -> Annotated[float,\"Accuracy\"]:\n",
    "    \"\"\"\n",
    "    Evaluates the accuracy of a trained model using the testing dataset.\n",
    "    \"\"\"\n",
    "    score = # Use the score function to calculate the accuracy\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline\n",
    "\n",
    "Finally, we have defined all the steps we need to train our model. In ZenML, we can now stack these steps together in one function to define our pipeline. To achieve this, we can simply define a new function, such as `training_pipeline()`, with a decorator `@pipeline` above. Thus, ZenML knows that this function represents our pipeline. Inside this function, we need to call all of our predefined steps, which will receive the returns of the previous steps as their input. \n",
    "For example, our `loading_data()` step returns the dataset, which then will be the input to our next step, the `split_data` step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pipeline\n",
    "def training_pipeline():\n",
    "    \"\"\"\n",
    "    Executes a full training pipeline on weather data to predict rain tomorrow.\n",
    "    \"\"\"\n",
    "    dataset = loading_data(\"Weather_Perth.csv\")\n",
    "    X_train,X_test,y_train,y_test = split_data(dataset,\"RainTomorrow\")\n",
    "    X_train,X_test = impute_missing_values(X_train,X_test)\n",
    "    X_train,X_test = encode_categorical_values(X_train,X_test)\n",
    "    X_train,X_test = scale_values(X_train,X_test)\n",
    "    y_train,y_test = label_encoding(y_train,y_test)\n",
    "    model, in_sample_score = model_trainer(X_train,y_train)\n",
    "    score = evaluate_model(model,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us execute our pipeline by calling our `training_pipeline()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the beginning, we explained that ZenML has the advantage of storing all the artifacts of our run. So, let us retrieve one of these artifacts, our test accuracy. To do so, we need to conduct the following steps:\n",
    "- First, we need to import `from zenml.client` the Pyhton `Client`\n",
    "- Second, we call the `get_artifact_version()` method on the Client object and store the responded artifact into a variable. As a parameter, we can pass the Artifact Name that we have defined in our step above. For example, to retrieve the test accuracy from the `evaluate_model()` function, we need to pass \"Accuracy\".\n",
    "    - ZenML stores all artifacts with a specific version ID; however, when we only pass the artifact name, we will receive the latest artifact as our response.\n",
    "- Finally, to receive the value, we call the `load()` function on the return value of step three."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zenml.client import Client\n",
    "artifact = Client().get_artifact_version(\"Accuracy\")\n",
    "artifact.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, retrieve the latest artifact of the in-sample score and compare it to the out-of-sample score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CODE HERE ###\n",
    "# print the in sample score\n",
    "### CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ZenML Dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last feature of ZenML we want to look at in this assignment is the Dashboard function. ZenML provides us, out of the box, a visualization of our pipelines and artifacts for every run we conducted. To use the dashboard, we can simply run `!zenml up` . Start the dashboard now and take a look at your pipeline. (Hint: you do not need to enter an email address if you do not want to receive news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zenml up"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
